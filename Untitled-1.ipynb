{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mainly doing this because dude I thought was my homie is talking to a girl he tried to set me up with previously\n",
    "#ill be good tho\n",
    "\n",
    "#a tokenizer just takes, in this case, a string and turns it into numbers and vice versa right? to create tokens\n",
    "\n",
    "#the encoder does string --> number\n",
    "#the decoder does number --> string\n",
    "\n",
    "CHARS = [\"a\", \"b\"]\n",
    "\n",
    "def tokenize(s): return [CHARS.index(c) for c in s]\n",
    "\n",
    "def untok(tok): return CHARS[tok]\n",
    "\n",
    "tokenize(\"aabaa\")\n",
    "untok(0) #a=0\n",
    "untok(1) #b=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "def linear(x, w, b):\n",
    "    return x @ w + b\n",
    "\n",
    "def attention(q, k, v, mask):\n",
    "    return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v\n",
    "\n",
    "def casual_self_attention(x, c_attn, c_proj):\n",
    "    x = linear(x, **c_attn)\n",
    "\n",
    "    q, k, v = np.split(x, 3, axis=-1)\n",
    "\n",
    "    causal_mask = (1 - np.tri(x.shape[0], dtype=x.dtype)) * -1e10\n",
    "\n",
    "    x = attention(q, k, v, causal_mask)\n",
    "    \n",
    "    x = linear(x, **c_proj)\n",
    "\n",
    "    return x\n",
    "\n",
    "def transformer_block(x, attn):\n",
    "    x = x + causal_self_attention(x, **attn)\n",
    "    return x\n",
    "def gpt(inputs, wte, wpe, blocks):\n",
    "    x = wte[inputs] + wpe[np.arange(len(inputs))]\n",
    "\n",
    "    for block in blocks:\n",
    "        x = transformer_block(x, **block)\n",
    "\n",
    "        return x @ wte.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CTX = 5\n",
    "N_VOCAB = 2\n",
    "N_EMBED = 8\n",
    "\n",
    "Lg = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = {\n",
    "    # EMBEDDING USAGE\n",
    "    #  P = Position embeddings (one-hot)\n",
    "    #  T = Token embeddings (one-hot, first is `a`, second is `b`)\n",
    "    #  V = Prediction scratch space\n",
    "    #\n",
    "    #       [P, P, P, P, P, T, T, V]\n",
    "    \"wte\": np.array(\n",
    "        # one-hot token embeddings\n",
    "        [\n",
    "            [0, 0, 0, 0, 0, 1, 0, 0],  # token `a` (id 0)\n",
    "            [0, 0, 0, 0, 0, 0, 1, 0],  # token `b` (id 1)\n",
    "        ]\n",
    "    ),\n",
    "    \"wpe\": np.array(\n",
    "        # one-hot position embeddings\n",
    "        [\n",
    "            [1, 0, 0, 0, 0, 0, 0, 0],  # position 0\n",
    "            [0, 1, 0, 0, 0, 0, 0, 0],  # position 1\n",
    "            [0, 0, 1, 0, 0, 0, 0, 0],  # position 2\n",
    "            [0, 0, 0, 1, 0, 0, 0, 0],  # position 3\n",
    "            [0, 0, 0, 0, 1, 0, 0, 0],  # position 4\n",
    "        ]\n",
    "    ),\n",
    "    \"blocks\": [\n",
    "        {\n",
    "            \"attn\": {\n",
    "                \"c_attn\": {  # generates qkv matrix\n",
    "                    \"b\": np.zeros(N_EMBED * 3),\n",
    "                    \"w\": np.array(\n",
    "                        # this is where the magic happens\n",
    "                        # fmt: off\n",
    "                        [\n",
    "                          [Lg, 0., 0., 0., 0., 0., 0., 0.,  # q\n",
    "                            1., 0., 0., 0., 0., 0., 0., 0.,  # k\n",
    "                              0., 0., 0., 0., 0., 0., 0., 0.], # v\n",
    "                          [Lg, Lg, 0., 0., 0., 0., 0., 0.,  # q\n",
    "                            0., 1., 0., 0., 0., 0., 0., 0.,  # k\n",
    "                              0., 0., 0., 0., 0., 0., 0., 0.], # v\n",
    "                          [0., Lg, Lg, 0., 0., 0., 0., 0.,  # q\n",
    "                            0., 0., 1., 0., 0., 0., 0., 0.,  # k\n",
    "                              0., 0., 0., 0., 0., 0., 0., 0.], # v\n",
    "                          [0., 0., Lg, Lg, 0., 0., 0., 0.,  # q\n",
    "                            0., 0., 0., 1., 0., 0., 0., 0.,  # k\n",
    "                              0., 0., 0., 0., 0., 0., 0., 0.], # v\n",
    "                          [0., 0., 0., Lg, Lg, 0., 0., 0.,  # q\n",
    "                            0., 0., 0., 0., 1., 0., 0., 0.,  # k\n",
    "                              0., 0., 0., 0., 0., 0., 0., 0.], # v\n",
    "                          [0., 0., 0., 0., 0., 0., 0., 0.,  # q\n",
    "                            0., 0., 0., 0., 0., 0., 0., 0.,  # k\n",
    "                              0., 0., 0., 0., 0., 0., 0., 1.], # v\n",
    "                          [0., 0., 0., 0., 0., 0., 0., 0.,  # q\n",
    "                            0., 0., 0., 0., 0., 0., 0., 0.,  # k\n",
    "                              0., 0., 0., 0., 0., 0., 0., -1], # v\n",
    "                          [0., 0., 0., 0., 0., 0., 0., 0.,  # q\n",
    "                            0., 0., 0., 0., 0., 0., 0., 0.,  # k\n",
    "                              0., 0., 0., 0., 0., 0., 0., 0.], # v\n",
    "                        ]\n",
    "                        # fmt: on\n",
    "                    ),\n",
    "                },\n",
    "                \"c_proj\": {  # weights to project attn result back to embedding space\n",
    "                    \"b\": [0, 0, 0, 0, 0, Lg, 0, 0],\n",
    "                    \"w\": np.array(\n",
    "                        [\n",
    "                            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0, -Lg, Lg, 0],\n",
    "                        ]\n",
    "                    ),\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(s, max_new_tokens=10):\n",
    "    tokens = tokenize(s)\n",
    "    while len(tokens) < len(s) + max_new_tokens:\n",
    "        logits = gpt(np.array(tokens [-5:]), **MODEL)\n",
    "        probs = softmax(logits)\n",
    "        pred = np.argmax(probs[-1])\n",
    "        tokens.append(pred)\n",
    "    return s + \" :: \" + \"\".join(untok(t) for t in tokens[len(s):])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a :: baabaabaab\n",
      "ba :: abaabaabaa\n",
      "abaab :: aabaabaaba\n"
     ]
    }
   ],
   "source": [
    "print(complete(\"a\"))\n",
    "print(complete(\"ba\"))\n",
    "print(complete(\"abaab\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[ 2048. -1023.]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[ 2048. -1023.]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[ 2048. -1023.]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[ 2048. -1023.]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[ 2048. -1023.]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[ 2048. -1023.]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[ 2048. -1023.]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[ 2048. -1023.]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "a (0): next=b (1) probs=[0. 1.] logits=[1.000e+00 1.024e+03]\n",
      "b (1): next=a (0) probs=[1. 0.] logits=[1.024e+03 1.000e+00]\n",
      "a (0): next=a (0) probs=[1. 0.] logits=[1025.    0.]\n",
      "ACCURACY: 100.0% (27 / 27)\n"
     ]
    }
   ],
   "source": [
    "test = \"aab\" * 10\n",
    "total, correct = 0, 0\n",
    "\n",
    "for i in range(2, len(test) - 1):\n",
    "    ctx = test[:i]\n",
    "    expected = test[i]\n",
    "    total += 1\n",
    "\n",
    "    if untok(predict(ctx)) == expected:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"ACCURACY: {correct / total * 100}% ({correct} / {total})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
